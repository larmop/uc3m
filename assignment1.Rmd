---
title: "R Notebook"
output: html_notebook
---

# Assignment 1

### Lara Monteser√≠n Placer

Every day, millions of users express their thoughts and emotions through tweets, creating a vast pool of valuable data. Analyzing the sentiment behind these tweets provides insights into public opinions, attitudes, and feelings.

In this study, our goal is to harness the power of sentiment analysis by building a classifier to predict whether a tweet carries a positive, negative, or neutral sentiment based on the words and expressions used by the users. This will be done through a brief naive Bayes analysis.

Some of the advantages of being able to classify tweets depending on its sentiment are:

1.  **Public Opinion Monitoring:** It offers real-time insights into public opinion on various topics, products, or events.

2.  **Brand Perception:** If performed around a brand on social media, it aids businesses in reinforcing loyalty with positive mentions and managing negative sentiments for effective reputation management.

3.  **Customer Feedback Analysis:** It provides companies with valuable insights into customer experiences, facilitating data-driven improvements in products and services.

4.  **Market Trends and Predictions:** It helps to identify emerging trends and anticipate shifts in public sentiment, empowering in making informed decisions.

5.  **Public Response to Events:** Crucial for public relations and crisis management, it offers a quick and efficient way to gauge how people react to specific events or announcements on social media.

![](foto.avif)

In this case study, we will use a dataset with 162961 instances of tweets published during the year 2021.

## 1. Introduction to the data

We took the dataset from Kaggle: <https://www.kaggle.com/datasets/saurabhshahane/twitter-sentiment-dataset>

The dataset Twitter_Data.csv includes the following 2 variables:

1.  **clean_text**: The complete text from the tweet. The type of the data is character.

2.  **category**: A unique code assigned to each text, indicating the sentiment code. The type of data is integer. There are 3 types of sentiments to classify the tweets in:

    -   Positive: 1

    -   Neutral: 0

    -   Negative: -1

```{r}

#Clear the system.
rm(list=ls())

library(tidyverse)
library(MASS)
library(e1071)
library(caret)
library(lubridate)
library(tidytext)
library(tm)
library(wordcloud)

#setwd("C:/User/laram/Desktop/Todo/UC3M/Third Bimester/Bayesian Learning/Assignment 1")

twitter <- read.csv("Twitter_Data.csv")

# Display column names in the dataset
colnames(twitter)

dim(twitter)
str(twitter)
summary(twitter)
```

## 2. Data cleaning analysis

We prepare the dataset for statistical analysis. We want to ensure that we are working with a reliable and accurate dataset.

Until now, we have 162980 instances.

The 2 columns have null values, 7 in category and 4 in clean_text. As this value is very low compared to the size of the dataset, we will just remove those instances, so we keep 162973 instances.

When first removing duplicates, we find out that there are just 2 duplicated values. Also, if we count the unique values in clean_text, there are only 162969, so these are the values that we keep to perform the statistical analysis.

Finally, we turn the tweets into a corpus in order to work with them. From here, we will clean the corpus: put everything in lower case. remove any numbers and punctuation, take out uninformative stop words and remove excess white space.

```{r}
# Counting NAs and empty values in each column
na_counts <- colSums(is.na(twitter) | twitter == "")
na_counts <- na_counts[order(-na_counts)]
print(na_counts)

# Removing instances with null values
twitter <- twitter[complete.cases(twitter), ]

#Current number of rows
n_rows <- nrow(twitter)
print(n_rows)

#Creates a logical vector duplicate_rows indicating whether each row in the data frame is a duplicate of a previous row
duplicate_rows <- twitter %>% duplicated.data.frame()

#Retains only the unique rows
library(dplyr)
twitter <- distinct(twitter)

#Number of rows after removing duplicates
n_rows2 <- nrow(twitter)
print(n_rows2)

# Duplicates based on column "clean_text"
twitter <- twitter %>% distinct(clean_text, .keep_all = TRUE)

n_rows3 <- nrow(twitter)
print(n_rows3)

# Turn the messages into a corpus.
corpus <- Corpus(VectorSource(twitter$clean_text))
inspect(corpus[1:5])

## CLEANING

# Put everything in lower case.
clean_corpus <- tm_map(corpus, tolower)
inspect(clean_corpus[1:5])

# Remove any numbers.
clean_corpus <- tm_map(clean_corpus, removeNumbers)
inspect(clean_corpus[1:5])

# Remove punctuation.
clean_corpus <- tm_map(clean_corpus, removePunctuation)
inspect(clean_corpus[1:5])

# Take out uninformative stop words.
stopwords("en")[1:10]
clean_corpus <- tm_map(clean_corpus, removeWords, stopwords("en"))
inspect(clean_corpus[1:5])

# Remove excess white space.
clean_corpus <- tm_map(clean_corpus, stripWhitespace)
inspect(clean_corpus[1:5])

# Check which tweets are positive, which neutral and which are negative.

pos_indices <- which(twitter$category == 1)
pos_indices[1:3]

neu_indices <- which(twitter$category == 0)
neu_indices[1:3]

neg_indices <- which(twitter$category == -1)
neg_indices[1:3]
```

## 3. Separate the data into a training set and a test set

It is always a good idea to separate from the beginning the training set (what the tool is going to see) from the testing set (used only to validate predictions).

```{r}
# split between training and testing sets
spl = createDataPartition(twitter$category, p = 0.8, list = FALSE)
twTrain = twitter[spl,]
twTest = twitter[-spl,]

str(twTrain)
summary(twTrain)
```

## 4. Use word clouds

-   To look at the different categories and explain any obvious differences between them

```{r}
wordcloud(clean_corpus[pos_indices], min.freq=40, scale=c(3,.5))
wordcloud(clean_corpus[neu_indices], min.freq=40, scale=c(3,.5))
wordcloud(clean_corpus[neg_indices], min.freq=40, scale=c(3,.5))
```

## 5. Naive Bayes analysis

to try to classify the data

## 6. Results

Report both in sample (training) results and out of sample (test) results.

## 7. Applying Laplace smoothing (Bayesian naive Bayes)

-   See if results improve

## 8. Conclusions and possible improvements
